{
  "jsonrpc": "2.0",
  "id": 31,
  "method": "tools/call",
  "params": {
    "name": "python-code-runner",
    "arguments": {
      "code": "import nltk\nimport re\nimport string\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nemail_content = \"\"\"*Why do you want to join us?*\\nI want to join WeDoGood because I deeply resonate with your mission of\\nusing technology to empower under-resourced organizations and individuals.\\nBuilding solutions that create real social impact excites me, and I believe\\nmy full-stack skills in *React.js, Next.js, Node.js, and PostgreSQL* can\\nhelp scale your platform while ensuring a seamless user experience.\\n------------------------------\\n\\n*Why makes you a suitable candidate for this role?*\\nI have hands-on experience developing end-to-end solutions, from designing\\nresponsive UIs with *React/Next.js* to building scalable backend services\\nwith *Node.js and SQL databases*. My projects, such as an *AI-powered\\ncareer platform* and a *conversational BI agent*, highlight my ability to\\ntake ownership, optimize performance, and deliver impactful results. I am\\neager to apply these skills to build purposeful technology at WeDoGood.\"\"\"\n\nprint(\"Starting email processing workflow...\")\n\n# Download stopwords if not already downloaded\ntry:\n    nltk.data.find(\"corpora/stopwords\")\n    print(\"NLTK stopwords already available\")\nexcept LookupError:\n    print(\"Downloading NLTK stopwords...\")\n    nltk.download(\"stopwords\")\n\n# Clean email content\nprint(\"Cleaning email content...\")\ncleaned_content = email_content.lower()\ncleaned_content = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", cleaned_content)\nstop_words = set(nltk.corpus.stopwords.words(\"english\"))\ncleaned_content = \" \".join([word for word in cleaned_content.split() if word not in stop_words])\n\nprint(f\"Cleaned content length: {len(cleaned_content)} characters\")\n\n# Extract keywords\nprint(\"Extracting keywords...\")\nvectorizer = CountVectorizer(max_features=5)\nfeature_names = vectorizer.fit_transform([cleaned_content]).get_feature_names_out()\nkeywords = list(feature_names)\n\nprint(f\"Keywords extracted: {keywords}\")\n\ndef categorize_and_triage(content, keywords, email_date, email_from, email_subject):\n    category = \"general_inquiry\"\n    priority = \"normal\"\n    summary = \"\"\n    reason = \"\"\n\n    if \"job\" in email_subject.lower() or \"position\" in email_subject.lower() or \"apply\" in content.lower():\n        category = \"general_inquiry\"\n        priority = \"high\"\n        summary = \"Application received for a job position. The candidate possesses full-stack skills in React.js, Next.js, Node.js, and PostgreSQL, with experience in AI-powered platforms and conversational BI agents.\"\n        reason = \"High priority due to incoming job application with relevant skills.\"\n    else:\n        summary = \"General inquiry received.\"\n        reason = \"Standard inquiry.\"\n\n    summary = summary[:280]\n    reason = reason[:140]\n\n    return {\n        \"category\": category,\n        \"summary\": summary,\n        \"priority\": priority,\n        \"reason\": reason,\n        \"email_date\": email_date,\n        \"email_from\": email_from,\n        \"email_subject\": email_subject\n    }\n\nemail_date = \"09/24/2025, 04:36 AM\"\nemail_from = \"ancdominater@gmail.com\"\nemail_subject = \"job position\"\n\nprint(\"Categorizing and triaging email...\")\ntriaged_email = categorize_and_triage(cleaned_content, keywords, email_date, email_from, email_subject)\n\nimport json\nprint(\"\\nFinal result:\")\nprint(json.dumps(triaged_email, indent=2))\nprint(\"\\nEmail processing workflow completed successfully!\")"
    }
  }
}